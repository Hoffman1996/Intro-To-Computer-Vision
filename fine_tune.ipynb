{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpEJM1c4UkYQ",
        "outputId": "aaf62f89-fef6-4d3c-a950-979ff14a69e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --upgrade --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qonJ0Pj8VLUx",
        "outputId": "1982b036-d251-43a8-d386-c6d83e4e3ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwDW-4eOTzxq"
      },
      "outputs": [],
      "source": [
        "def train_model(model : YOLO) -> None:\n",
        "    start_time = time.time()\n",
        "    model_name = f'yolov8{MODEL_SIZE}-img_size_{IMG_SIZE}_layers_frozen_{LAYER_FREEZE}_{DATE}'\n",
        "    # By default, the model trains on a single GPU\n",
        "    model.train(\n",
        "        data=curr_data_yaml,\n",
        "        imgsz=IMG_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        freeze=LAYER_FREEZE,\n",
        "        amp=True,\n",
        "        cache=\"disk\", # If the size of your dataset is larger than your available memory, cache to disk instead with cache=\"disk\", else use cache=True to keep the dataset in memory\n",
        "        save=True,\n",
        "        save_period=10,\n",
        "        name=model_name,\n",
        "        hsv_h=HSV_H,\n",
        "        hsv_s=HSV_S,\n",
        "        hsv_v=HSV_V,\n",
        "        degrees=DEGREES,\n",
        "        translate=TRANSLATE,\n",
        "        scale=SCALE,\n",
        "        shear=SHEAR,\n",
        "        perspective=PERSPECTIVE,\n",
        "        flipud=FLIPUD,\n",
        "        fliplr=FLIPLR,\n",
        "        # bgr=BGR,\n",
        "        mosaic=MOSAIC,\n",
        "        mixup=MIXUP,\n",
        "        copy_paste=COPY_PASTE,\n",
        "        erasing=ERASING,\n",
        "        crop_fraction=CROP_FRACTION\n",
        "    )\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(\"Time to train: \", training_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlCZ8l03Tzxk"
      },
      "outputs": [],
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import tqdm\n",
        "\n",
        "# Change these parameters to fit your needs\n",
        "EPOCHS = 100\n",
        "NUM_TRAIN_LOOPS = 1\n",
        "IMG_SIZE = 1032 # YOLOv8 default is 640\n",
        "LAYER_FREEZE = 0 # Number of layers to freeze\n",
        "\n",
        "# Amount to use different data augmentations\n",
        "HSV_H = 0.1  # Modifies hue\n",
        "HSV_S = 0.7  # Modifies saturation\n",
        "HSV_V = 0.4  # Modifies value (brightness)\n",
        "DEGREES = 0.4  # Rotates the image randomly\n",
        "TRANSLATE = 0.3\n",
        "SCALE = 0.5\n",
        "SHEAR = 0.01\n",
        "PERSPECTIVE = 0.001\n",
        "FLIPUD = 0.3\n",
        "FLIPLR = 0.3\n",
        "BGR = 0.1  # Flips channels from RGB to BGR\n",
        "MOSAIC = 0.5\n",
        "MIXUP = 0.5\n",
        "COPY_PASTE = 0.4\n",
        "ERASING = 0.2\n",
        "CROP_FRACTION = 0.1\n",
        "\n",
        "# Dictionary to weight dataset (randomly removed images with given probability\n",
        "# or duplicate images)\n",
        "DATASET_WEIGHTS = {\n",
        "    'large': 0.1 # Remove extra images from dataset with no frameskipping\n",
        "}\n",
        "\n",
        "# Whether or not to use hyperparameter tuning\n",
        "HYPERPARAMETER_TUNING = False\n",
        "# Whether or not to use ray tune for hyperparameter sweep / tuning\n",
        "USE_RAY_TUNE = False\n",
        "# Number of iterations for hyperparameter sweep / tuning\n",
        "TUNE_ITERS = 5\n",
        "\n",
        "CURR_DIR = '/content/drive/MyDrive/Intro to computer vision/Final'\n",
        "WORKSPACE_DIR = os.path.dirname(CURR_DIR)\n",
        "DATASETS_DIR ='/content/drive/MyDrive/Intro to computer vision/Final/train_validation_images'\n",
        "DATA_YAML = WORKSPACE_DIR + '/dataset.yaml'\n",
        "\n",
        "# Percetnage of dataset to use for training\n",
        "TRAIN_PERCENTAGE = 1.0\n",
        "\n",
        "# Whether or not to keep empty frames (frames with no labels) in the dataset\n",
        "KEEP_EMPTY_FRAMES = True\n",
        "# Percentage of empty frames to keep in the dataset if KEEP_EMPTY_FRAMES is True (randomly sampled)\n",
        "PERCENTAGE_EMPTY_FRAMES_TO_KEEP = 0.8\n",
        "\n",
        "# Flag to resume training from a previous checkpoint (false if training from scratch)\n",
        "RESUME_TRAINING = False\n",
        "RESUME_TRAINING_PATH = WORKSPACE_DIR + 'runs/train/exp/weights/best.pt'\n",
        "# Size of YOLOv8 model\n",
        "MODEL_SIZE = 'n' # 'n' ,'s', 'm', 'l', 'x'\n",
        "\n",
        "# Path to trained model weights\n",
        "MODELS_PATH = WORKSPACE_DIR + '/models/'\n",
        "\n",
        "# This line prevents the Kernel from crashing when running model.train() which calls a plotting function\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "ONNX_BATCH_SIZE = 4\n",
        "\n",
        "# Todays data + Batch size + epochs\n",
        "DATE = time.strftime('%Y-%m-%d-%H-%M-%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn4DzdiKTzxm"
      },
      "source": [
        "# Check System Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxK8RZ0TTzxn",
        "outputId": "549e8445-05cf-4ae5-99dd-4cbbaacdc7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: False\n",
            "Torch CUDA Version: 12.4\n"
          ]
        }
      ],
      "source": [
        "print(\"CUDA Available: \" + str(torch.cuda.is_available()))\n",
        "print(\"Torch CUDA Version: \" + str(torch.version.cuda))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Gg4E48Tzxn",
        "outputId": "b832e67b-eda1-4e30-8779-f5e9150ce2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.9/107.7 GB disk)\n",
            "\n",
            "OS                  Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "Environment         Colab\n",
            "Python              3.11.13\n",
            "Install             pip\n",
            "Path                /usr/local/lib/python3.11/dist-packages/ultralytics\n",
            "RAM                 12.67 GB\n",
            "Disk                41.9/107.7 GB\n",
            "CPU                 Intel Xeon 2.20GHz\n",
            "CPU count           2\n",
            "GPU                 None\n",
            "GPU count           None\n",
            "CUDA                None\n",
            "\n",
            "numpy               ✅ 2.0.2>=1.23.0\n",
            "matplotlib          ✅ 3.10.0>=3.3.0\n",
            "opencv-python       ✅ 4.11.0.86>=4.6.0\n",
            "pillow              ✅ 11.2.1>=7.1.2\n",
            "pyyaml              ✅ 6.0.2>=5.3.1\n",
            "requests            ✅ 2.32.3>=2.23.0\n",
            "scipy               ✅ 1.15.3>=1.4.1\n",
            "torch               ✅ 2.6.0+cu124>=1.8.0\n",
            "torch               ✅ 2.6.0+cu124!=2.4.0,>=1.8.0; sys_platform == \"win32\"\n",
            "torchvision         ✅ 0.21.0+cu124>=0.9.0\n",
            "tqdm                ✅ 4.67.1>=4.64.0\n",
            "psutil              ✅ 5.9.5\n",
            "py-cpuinfo          ✅ 9.0.0\n",
            "pandas              ✅ 2.2.2>=1.1.4\n",
            "ultralytics-thop    ✅ 2.0.14>=2.0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'OS': 'Linux-6.1.123+-x86_64-with-glibc2.35',\n",
              " 'Environment': 'Colab',\n",
              " 'Python': '3.11.13',\n",
              " 'Install': 'pip',\n",
              " 'Path': '/usr/local/lib/python3.11/dist-packages/ultralytics',\n",
              " 'RAM': '12.67 GB',\n",
              " 'Disk': '41.9/107.7 GB',\n",
              " 'CPU': 'Intel Xeon 2.20GHz',\n",
              " 'CPU count': 2,\n",
              " 'GPU': None,\n",
              " 'GPU count': None,\n",
              " 'CUDA': None,\n",
              " 'Package Info': {'numpy': '✅ 2.0.2>=1.23.0',\n",
              "  'matplotlib': '✅ 3.10.0>=3.3.0',\n",
              "  'opencv-python': '✅ 4.11.0.86>=4.6.0',\n",
              "  'pillow': '✅ 11.2.1>=7.1.2',\n",
              "  'pyyaml': '✅ 6.0.2>=5.3.1',\n",
              "  'requests': '✅ 2.32.3>=2.23.0',\n",
              "  'scipy': '✅ 1.15.3>=1.4.1',\n",
              "  'torch': '✅ 2.6.0+cu124!=2.4.0,>=1.8.0; sys_platform == \"win32\"',\n",
              "  'torchvision': '✅ 0.21.0+cu124>=0.9.0',\n",
              "  'tqdm': '✅ 4.67.1>=4.64.0',\n",
              "  'psutil': '✅ 5.9.5',\n",
              "  'py-cpuinfo': '✅ 9.0.0',\n",
              "  'pandas': '✅ 2.2.2>=1.1.4',\n",
              "  'ultralytics-thop': '✅ 2.0.14>=2.0.0'}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Check to make sure CUDA is available and does not say \"None\"\n",
        "ultralytics.utils.checks.collect_system_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQG8uclKTzxn"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9cLFOFXTzxn"
      },
      "outputs": [],
      "source": [
        "def generate_empty_label(label_dst : os.PathLike) -> None:\n",
        "    '''\n",
        "    Generates an empty label file with the correct format to handle empty frames.\n",
        "    '''\n",
        "    with open(label_dst, 'w') as f:\n",
        "        f.write(\"\")\n",
        "\n",
        "def choose_dataset_weight(img_src : os.PathLike, dataset_weight : dict, weighted_frames : dict, frames_removed : dict) -> int:\n",
        "    '''\n",
        "    Returns a dataset weight to use dataset_weights dictionary. Uses the file path to determine the dataset.\n",
        "    '''\n",
        "    dataset_name = img_src.split(\"/\")[-3]\n",
        "    for dataset, weight in dataset_weight.items():\n",
        "        if dataset in dataset_name:\n",
        "            # If weight is greater than 1, keep the frame and create additional frames with the same image and label\n",
        "            if weight > 1:\n",
        "                weighted_frames[dataset] = weighted_frames.get(dataset, 0) + (weight - 1)\n",
        "                return weight\n",
        "            # If weight is less than 1, randomly choose to keep the frame or not\n",
        "            else:\n",
        "                # Keep the frame with probability weight\n",
        "                if random.random() < weight:\n",
        "                    return 1\n",
        "                # Discard the frame with probability 1 - weight\n",
        "                else:\n",
        "                    frames_removed[dataset] = frames_removed.get(dataset, 0) + 1\n",
        "                    return 0\n",
        "    return 1\n",
        "\n",
        "def copy_data_yaml(label_src : os.PathLike, img_src : os.PathLike, label_dst : os.PathLike, img_dst : os.PathLike, empty_frames_kept : int, weighted_frames : dict, frames_removed : dict) -> None:\n",
        "    '''\n",
        "    Copies the images and labels from one directory to another. Also handles the case where the label file is empty (i.e. does not exist).\n",
        "    '''\n",
        "    if not os.path.exists(label_src):\n",
        "        # print(\"Empty label file detected:\", label_src)\n",
        "        if KEEP_EMPTY_FRAMES:\n",
        "            if random.random() < PERCENTAGE_EMPTY_FRAMES_TO_KEEP:\n",
        "                empty_frames_kept += 1\n",
        "                for i in range(choose_dataset_weight(img_src, DATASET_WEIGHTS, weighted_frames, frames_removed)):\n",
        "                    img_dst_with_weight = img_dst[:-4] + \"_\" + str(i) + \".jpg\"\n",
        "                    label_dst_with_weight = label_dst[:-4] + \"_\" + str(i) + \".txt\"\n",
        "                    shutil.copy(img_src, img_dst_with_weight)\n",
        "                    generate_empty_label(label_dst_with_weight)\n",
        "                    # normalize_image(img_dst)\n",
        "    else:\n",
        "        for i in range(choose_dataset_weight(img_src, DATASET_WEIGHTS, weighted_frames, frames_removed)):\n",
        "            img_dst_with_weight = img_dst[:-4] + \"_\" + str(i) + \".jpg\"\n",
        "            label_dst_with_weight = label_dst[:-4] + \"_\" + str(i) + \".txt\"\n",
        "            shutil.copy(img_src, img_dst_with_weight)\n",
        "            shutil.copy(label_src, label_dst_with_weight)\n",
        "            # normalize_image(img_dst)\n",
        "\n",
        "def normalize_image(img_path : os.PathLike) -> None:\n",
        "    '''\n",
        "    Normalizes the image to the correct format for YOLOv8.\n",
        "    '''\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (640, 640))\n",
        "    cv2.imwrite(img_path, img)\n",
        "\n",
        "def format_datasets(datasets_path : os.PathLike, data_yaml : os.PathLike) -> None:\n",
        "    \"\"\"\n",
        "    Takes in a directory of datasets where each dataset is in the format of a COCO dataset\n",
        "    and then formats the datasets into a single dataset that YOLOv8 can use for training\n",
        "    placed in the 'data/' directory. This function will delete the 'data/' directory and recreate\n",
        "    it. The data.yaml file must be created manually and will be copied over to the 'data/'\n",
        "    directory. The function will also split the data into training, validation, and test sets.\n",
        "\n",
        "    Args:\n",
        "        datasets_path (os.PathLike): The path to the directory containing the datasets.\n",
        "        data_yaml (os.PathLike): The path to the data.yaml file specifying the dataset. This must be\n",
        "            created manually.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    assert os.path.exists(datasets_path), f\"The dataset path, {datasets_path}, does not exist.\"\n",
        "    assert os.path.exists(data_yaml), f\"The data.yaml file, {data_yaml}, does not exist.\"\n",
        "\n",
        "    print(\"Extracting sim images from:\", datasets_path, \"for training/validation data\")\n",
        "\n",
        "    # Get all images and labels from the datasets\n",
        "    datasets_labels = []\n",
        "    for dataset_path in os.listdir(datasets_path):\n",
        "        full_path = os.path.join(datasets_path, dataset_path)\n",
        "        for img_file in os.listdir(full_path + \"/images/\"):\n",
        "            datasets_labels.append([full_path + \"/images/\" + img_file, full_path + \"/labels/\" + img_file[:-4] + \".txt\", dataset_path])\n",
        "\n",
        "    # Sort images by filename\n",
        "    datasets_labels = sorted(datasets_labels, key = lambda x: x[0])\n",
        "    # datasets_labels = sorted(datasets_labels, key = lambda x: x[0])\n",
        "\n",
        "    # Shuffle images deterministically with seed\n",
        "    random.seed(0)\n",
        "    random.shuffle(datasets_labels)\n",
        "\n",
        "    # Split 70% training, 20% validation, 10% test\n",
        "    training_data = datasets_labels[:len(datasets_labels) * 7 // 10]\n",
        "    valid_data = datasets_labels[len(datasets_labels) * 7 // 10 :len(datasets_labels) * 9 // 10]\n",
        "    test_data = datasets_labels[len(datasets_labels) * 9 // 10 :]\n",
        "\n",
        "\n",
        "    # Create the directories for the training, validation, and test data\n",
        "    if os.path.exists(\"../data/\"):\n",
        "        print(\"Deleting and recreating 'data/' folder...\")\n",
        "        shutil.rmtree(\"../data/\")\n",
        "    os.mkdir(\"../data/\")\n",
        "    os.mkdir(\"../data/train/\")\n",
        "    os.mkdir(\"../data/train/images/\")\n",
        "    os.mkdir(\"../data/train/labels/\")\n",
        "    os.mkdir(\"../data/valid/\")\n",
        "    os.mkdir(\"../data/valid/images/\")\n",
        "    os.mkdir(\"../data/valid/labels/\")\n",
        "    os.mkdir(\"../data/test/\")\n",
        "    os.mkdir(\"../data/test/images/\")\n",
        "    os.mkdir(\"../data/test/labels/\")\n",
        "\n",
        "    # Copy over images and labels to new directories\n",
        "    print(\"Copying images and labels to new directories...\")\n",
        "    print(\"Copying training data:\")\n",
        "\n",
        "    # Create a new image number to avoid overwriting images in the same chance they have the same name\n",
        "    new_image_uuid = 0\n",
        "    empty_frames_kept = 0\n",
        "    weighted_frames = {}\n",
        "    removed_frames = {}\n",
        "    train_frames = 0\n",
        "    valid_frames = 0\n",
        "    test_frames = 0\n",
        "    for img_src, label_src, dataset_path in tqdm.tqdm(training_data):\n",
        "        if (random.random() < TRAIN_PERCENTAGE):\n",
        "            new_image_name = img_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".jpg\"\n",
        "            new_label_name = label_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".txt\"\n",
        "            img_dst = os.path.join(\"../data/train/images/\", dataset_path + \"_\" + new_image_name)\n",
        "            label_dst = os.path.join(\"../data/train/labels/\", dataset_path + \"_\" + new_label_name)\n",
        "            copy_data_yaml(label_src, img_src, label_dst, img_dst, empty_frames_kept, weighted_frames, removed_frames)\n",
        "            new_image_uuid += 1\n",
        "            train_frames += 1\n",
        "    for img_src, label_src, dataset_path in tqdm.tqdm(valid_data):\n",
        "        new_image_name = img_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".jpg\"\n",
        "        new_label_name = label_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".txt\"\n",
        "        img_dst = os.path.join(\"../data/valid/images/\", dataset_path + \"_\" + new_image_name)\n",
        "        label_dst = os.path.join(\"../data/valid/labels/\", dataset_path + \"_\" + new_label_name)\n",
        "        copy_data_yaml(label_src, img_src, label_dst, img_dst, empty_frames_kept, weighted_frames, removed_frames)\n",
        "        new_image_uuid += 1\n",
        "        valid_frames += 1\n",
        "    for img_src, label_src, dataset_path in tqdm.tqdm(test_data):\n",
        "        new_image_name = img_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".jpg\"\n",
        "        new_label_name = label_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".txt\"\n",
        "        img_dst = os.path.join(\"../data/test/images/\", dataset_path + \"_\" + new_image_name)\n",
        "        label_dst = os.path.join(\"../data/test/labels/\", dataset_path + \"_\" + new_label_name)\n",
        "        copy_data_yaml(label_src, img_src, label_dst, img_dst, empty_frames_kept, weighted_frames, removed_frames)\n",
        "        new_image_uuid += 1\n",
        "        test_frames += 1\n",
        "\n",
        "    # Copy over data.yaml file from root directory\n",
        "    shutil.copy(data_yaml, \"../data/\")\n",
        "    print(\"Copied over 'data.yaml' file\")\n",
        "    print(\"Number of empty frames kept: \", empty_frames_kept)\n",
        "\n",
        "    print(\"Number of training frames: \", train_frames)\n",
        "    print(\"Number of validation frames: \", valid_frames)\n",
        "    print(\"Number of test frames: \", test_frames)\n",
        "    print(\"Additional weighted frames created for each dataset: \", weighted_frames)\n",
        "    print(\"Number of frames removed for each dataset: \", removed_frames)\n",
        "    print(\"Finished creating directories for YOLOv8 training pipeline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8JYjQPWTzxo"
      },
      "outputs": [],
      "source": [
        "format_datasets(DATASETS_DIR, DATA_YAML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKR2scLwTzxo"
      },
      "source": [
        "# Load Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DpGM2r9Tzxp"
      },
      "outputs": [],
      "source": [
        "def choose_model_size() -> str:\n",
        "    \"\"\"\n",
        "    Takes the global variable MODEL_SIZE and returns the corresponding string\n",
        "    to pass to the YOLO class and print the model parameter size.\n",
        "\n",
        "    Returns:\n",
        "        str: The model string to pass to the YOLO class.\n",
        "    \"\"\"\n",
        "    if MODEL_SIZE == 'n':\n",
        "        print(\"Using YOLOv8 Nano model\")\n",
        "        return 'yolov8n-seg.pt'\n",
        "    elif MODEL_SIZE == 's':\n",
        "        print(\"Using YOLOv8 Small model\")\n",
        "        return 'yolov8s-seg.pt'\n",
        "    elif MODEL_SIZE == 'm':\n",
        "        print(\"Using YOLOv8 Medium model\")\n",
        "        return 'yolov8m-seg.pt'\n",
        "    elif MODEL_SIZE == 'l':\n",
        "        print(\"Using YOLOv8 Large model\")\n",
        "        return 'yolov8l-seg.pt'\n",
        "    elif MODEL_SIZE == 'x':\n",
        "        print(\"Using YOLOv8 Extra Large model\")\n",
        "        return 'yolov8x-seg.pt'\n",
        "\n",
        "# Load yolov8 nano segmentation model\n",
        "if RESUME_TRAINING:\n",
        "    model = YOLO(RESUME_TRAINING_PATH)\n",
        "# Load yolov8 nano segmentation model\n",
        "else:\n",
        "    model = YOLO(choose_model_size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23KG3t-5Tzxp"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdnPqgHlTzxq"
      },
      "outputs": [],
      "source": [
        "# Find dataset images\n",
        "data_dir = CURR_DIR + '/../data/'\n",
        "curr_data_yaml = data_dir + 'data.yaml'\n",
        "TEST_PATH = data_dir + '/test/images/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqHocFJ_Tzxq"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og94KWk4Tzxq"
      },
      "outputs": [],
      "source": [
        "def tune_model(model : YOLO) -> None:\n",
        "    # Runs a hyperparameter sweep and selects the best hyperparameters\n",
        "    if HYPERPARAMETER_TUNING:\n",
        "        model.tune(use_ray=USE_RAY_TUNE, iterations=TUNE_ITERS)\n",
        "    else:\n",
        "        print(\"Skipping hyperparameter tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3XO3kZDTzxr"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jPGrvLZTzxr"
      },
      "outputs": [],
      "source": [
        "def test_model(model : YOLO, test_results_path: os.PathLike) -> None:\n",
        "    \"\"\"\n",
        "    Test the fine-tuned model on test images and save the results.\n",
        "\n",
        "    Parameters:\n",
        "        model (YOLO): The fine-tuned YOLO model.\n",
        "        test_results_path (os.PathLike): The path to save the test results.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    # Make sure the test save path exists\n",
        "    if not os.path.exists(test_results_path):\n",
        "        os.makedirs(test_results_path)\n",
        "\n",
        "    # Inferencee fine-tuned model on test images and save results\n",
        "    for file in os.listdir(TEST_PATH):\n",
        "        file_path = os.path.join(TEST_PATH, file)\n",
        "        output = model.predict(file_path)\n",
        "        save_path = os.path.join(test_results_path, file)\n",
        "        cv2.imwrite(save_path, output[0].plot())\n",
        "\n",
        "    print(\"Inference on test set complete. Results saved to: \", test_results_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKuelXD_Tzxr"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIofbELbTzxr"
      },
      "outputs": [],
      "source": [
        "epochs_done = 0\n",
        "for _ in range(NUM_TRAIN_LOOPS):\n",
        "    print(f\"Starting training loop starting on epoch {epochs_done}\")\n",
        "    train_model(model)\n",
        "    epochs_done += EPOCHS\n",
        "    tune_model(model)\n",
        "    test_results_path = data_dir + '/test/annotation_results' + f'_{epochs_done}epochs'\n",
        "    test_model(model, test_results_path)\n",
        "    model_name = f\"yolov8{MODEL_SIZE}_{DATE}_batch{ONNX_BATCH_SIZE}_{EPOCHS}epochs\"\n",
        "    model_path = MODELS_PATH + model_name + '.pt'\n",
        "    model.save(model_path)\n",
        "    # Export the model as an .onnx file\n",
        "    model.export(format='onnx', batch=ONNX_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZohwcNsTzxs"
      },
      "source": [
        "# Save Weights and Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYQ0s--VTzxs"
      },
      "outputs": [],
      "source": [
        "# Export the model as an .onnx file\n",
        "model.export(format='onnx', batch=ONNX_BATCH_SIZE)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}